{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vanilla VAE implementation for EvilMouse Data.\n",
    "This uses a 3D encoder/decoder structure, since data is time-series of 2D images\n",
    "and we wish to convolve over pt closer in time.\n",
    "This is for mouse video data from Musall et al. (2019) which has 160x120 frames.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import h5py\n",
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "from umap import UMAP\n",
    "import torch\n",
    "from torch.distributions import LowRankMultivariateNormal\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "SUMMARY_WRITER_PATH = \"/home/achint/Practice_code/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SHAPE = (160, 120, 31)\n",
    "X_DIM = np.prod(X_SHAPE)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, save_dir='', lr=1e-3, z_dim=32, model_precision=10, device_name=\"auto\"):\n",
    "        super(VAE, self).__init__()\n",
    "        self.save_dir = save_dir\n",
    "        self.lr = lr\n",
    "        self.z_dim = z_dim\n",
    "        self.model_precision = model_precision\n",
    "        assert device_name != \"cuda\" or torch.cuda.is_available()\n",
    "        if device_name == \"auto\":\n",
    "            device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.device = torch.device(device_name)\n",
    "        if self.save_dir != '' and not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        self._build_network()\n",
    "        self.optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "        self.epoch = 0\n",
    "        self.loss = {'train':{}, 'test':{}}\n",
    "        #init summary writter instance for TB logging\n",
    "#         ts = datetime.datetime.now().date()\n",
    "#         self.writer = SummaryWriter(log_dir = os.path.join(self.save_dir, 'run', ts.strftime('%m_%d_%Y')))\n",
    "        self.writer = SummaryWriter(log_dir = SUMMARY_WRITER_PATH)\n",
    "\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _build_network(self):\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv3d(1,8,3,1,padding=1)\n",
    "        self.conv2 = nn.Conv3d(8,8,3,2,padding=1)\n",
    "        self.conv3 = nn.Conv3d(8,16,3,1,padding=1)\n",
    "        self.conv4 = nn.Conv3d(16,16,3,2,padding=1)\n",
    "        self.conv5 = nn.Conv3d(16,24,3,1,padding=1)\n",
    "        self.conv6 = nn.Conv3d(24,24,3,2,padding=1)\n",
    "        self.conv7 = nn.Conv3d(24,32,3,1,padding=1)\n",
    "        self.conv8 = nn.Conv3d(32,32,3,2,padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(1)\n",
    "        self.bn2 = nn.BatchNorm3d(8)\n",
    "        self.bn3 = nn.BatchNorm3d(8)\n",
    "        self.bn4 = nn.BatchNorm3d(16)\n",
    "        self.bn5 = nn.BatchNorm3d(16)\n",
    "        self.bn6 = nn.BatchNorm3d(24)\n",
    "        self.bn7 = nn.BatchNorm3d(24)\n",
    "        self.bn8 = nn.BatchNorm3d(32)\n",
    "        self.fc1 = nn.Linear(5120, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc31 = nn.Linear(256, 64)\n",
    "        self.fc32 = nn.Linear(256, 64)\n",
    "        self.fc33 = nn.Linear(256, 64)\n",
    "        self.fc41 = nn.Linear(64, self.z_dim)\n",
    "        self.fc42 = nn.Linear(64, self.z_dim)\n",
    "        self.fc43 = nn.Linear(64, self.z_dim)\n",
    "        #Decoder\n",
    "        self.fc5 = nn.Linear(self.z_dim,64)\n",
    "        self.fc6 = nn.Linear(64,256)\n",
    "        self.fc7 = nn.Linear(256,1024)\n",
    "        self.fc8 = nn.Linear(1024,5120)\n",
    "        self.convt1 = nn.ConvTranspose3d(32,24,3,1,padding=1)\n",
    "        self.convt2 = nn.ConvTranspose3d(24,24,3,2,padding=1,output_padding=(1, 0, 1))\n",
    "        self.convt3 = nn.ConvTranspose3d(24,16,3,1,padding=1)\n",
    "        self.convt4 = nn.ConvTranspose3d(16,16,3,2,padding=1,output_padding=1)\n",
    "        self.convt5 = nn.ConvTranspose3d(16,8,3,1,padding=1)\n",
    "        self.convt6 = nn.ConvTranspose3d(8,8,3,2,padding=1,output_padding=1)\n",
    "        self.convt7 = nn.ConvTranspose3d(8,4,3,1,padding=1)\n",
    "        self.convt8 = nn.ConvTranspose3d(4,4,3,2,padding=1, output_padding=(1, 1, 0))\n",
    "        self.convt9 = nn.ConvTranspose3d(4,1,3,1,padding=1)\n",
    "        self.bn9 = nn.BatchNorm3d(32)\n",
    "        self.bn10 = nn.BatchNorm3d(24)\n",
    "        self.bn11 = nn.BatchNorm3d(24)\n",
    "        self.bn12 = nn.BatchNorm3d(16)\n",
    "        self.bn13 = nn.BatchNorm3d(16)\n",
    "        self.bn14 = nn.BatchNorm3d(8)\n",
    "        self.bn15 = nn.BatchNorm3d(8)\n",
    "        self.bn16 = nn.BatchNorm3d(4)\n",
    "        self.bn17 = nn.BatchNorm3d(4)\n",
    "\n",
    "\n",
    "    def _get_layers(self):\n",
    "        \"\"\"Return a dictionary mapping names to network layers.\"\"\"\n",
    "        return {'fc1':self.fc1, 'fc2':self.fc2, 'fc31':self.fc31,\n",
    "                'fc32':self.fc32, 'fc33':self.fc33, 'fc41':self.fc41,\n",
    "                'fc42':self.fc42, 'fc43':self.fc43, 'fc5':self.fc5,\n",
    "                'fc6':self.fc6, 'fc7':self.fc7, 'fc8':self.fc8, 'bn1':self.bn1,\n",
    "                'bn2':self.bn2, 'bn3':self.bn3, 'bn4':self.bn4, 'bn5':self.bn5,\n",
    "                'bn6':self.bn6, 'bn7':self.bn7, 'bn8':self.bn8, 'bn9':self.bn9,\n",
    "                'bn10':self.bn10, 'bn11':self.bn11, 'bn12':self.bn12,\n",
    "                'bn13':self.bn13, 'bn14':self.bn14, 'bn15':self.bn15,\n",
    "                'bn16':self.bn16, 'bn17':self.bn17,'conv1':self.conv1,\n",
    "                'conv2':self.conv2, 'conv3':self.conv3, 'conv4':self.conv4,\n",
    "                'conv5':self.conv5, 'conv6':self.conv6, 'conv7':self.conv7,\n",
    "                'conv8':self.conv8,'convt1':self.convt1, 'convt2':self.convt2,\n",
    "                'convt3':self.convt3, 'convt4':self.convt4,'convt5':self.convt5,\n",
    "                'convt6':self.convt6,'convt7':self.convt7, 'convt8':self.convt8,\n",
    "                'convt9':self.convt9}\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(self.bn1(x)))\n",
    "        x = F.relu(self.conv2(self.bn2(x)))\n",
    "        x = F.relu(self.conv3(self.bn3(x)))\n",
    "        x = F.relu(self.conv4(self.bn4(x)))\n",
    "        x = F.relu(self.conv5(self.bn5(x)))\n",
    "        x = F.relu(self.conv6(self.bn6(x)))\n",
    "        x = F.relu(self.conv7(self.bn7(x)))\n",
    "        x = F.relu(self.conv8(self.bn8(x)))\n",
    "        x = x.view(-1, 5120)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mu = F.relu(self.fc31(x))\n",
    "        mu = self.fc41(mu)\n",
    "        u = F.relu(self.fc32(x))\n",
    "        u = self.fc42(u).unsqueeze(-1) # Last dimension is rank \\Sigma = 1.\n",
    "        d = F.relu(self.fc33(x))\n",
    "        d = torch.exp(self.fc43(d)) # d must be positive.\n",
    "        return mu, u, d\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = F.relu(self.fc5(z))\n",
    "        z = F.relu(self.fc6(z))\n",
    "        z = F.relu(self.fc7(z))\n",
    "        z = F.relu(self.fc8(z))\n",
    "        z = z.view(-1,32,10,8,2)\n",
    "        z = F.relu(self.convt1(self.bn9(z)))\n",
    "        z = F.relu(self.convt2(self.bn10(z)))\n",
    "        z = F.relu(self.convt3(self.bn11(z)))\n",
    "        z = F.relu(self.convt4(self.bn12(z)))\n",
    "        z = F.relu(self.convt5(self.bn13(z)))\n",
    "        z = F.relu(self.convt6(self.bn14(z)))\n",
    "        z = self.convt7(self.bn15(z))\n",
    "        z = self.convt8(self.bn16(z))\n",
    "        z = self.convt9(self.bn17(z))\n",
    "        z = z.view(-1, X_DIM)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, return_latent_rec=False, train_mode=False):\n",
    "        mu, u, d = self.encode(x)\n",
    "        latent_dist = LowRankMultivariateNormal(mu, u, d)\n",
    "        z = latent_dist.rsample()\n",
    "        x_rec = self.decode(z)\n",
    "        if train_mode: #log reconstructions\n",
    "            batch_size = x_rec.detach().cpu().numpy().shape[0]\n",
    "            self.log_reconstruction(x_rec.detach().cpu().numpy(), batch_size, log_type='train')\n",
    "        # E_{q(z|x)} p(z)\n",
    "        elbo = -0.5 * (torch.sum(torch.pow(z,2)) + self.z_dim * np.log(2*np.pi))\n",
    "        # E_{q(z|x)} p(x|z)\n",
    "        pxz_term = -0.5 * X_DIM * (np.log(2*np.pi/self.model_precision))\n",
    "        l2s = torch.sum(torch.pow(x.view(x.shape[0],-1) - x_rec, 2), dim=1)\n",
    "        pxz_term = pxz_term - 0.5 * self.model_precision * torch.sum(l2s)\n",
    "        elbo = elbo + pxz_term\n",
    "        # H[q(z|x)]\n",
    "        elbo = elbo + torch.sum(latent_dist.entropy())\n",
    "        if return_latent_rec:\n",
    "            return -elbo, z.detach().cpu().numpy(), \\\n",
    "            x_rec.view(-1, X_SHAPE[0], X_SHAPE[1], X_SHAPE[2]).detach().cpu().numpy()\n",
    "        return -elbo\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        self.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            self.optimizer.zero_grad()\n",
    "            frame = data['frame']\n",
    "            frame = frame.to(self.device)\n",
    "            loss = self.forward(frame, train_mode=True)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        print('Epoch: {} Average loss: {:.4f}'.format(self.epoch, \\\n",
    "        train_loss))\n",
    "        self.epoch += 1\n",
    "        return train_loss\n",
    "\n",
    "    def test_epoch(self, test_loader):\n",
    "        self.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                frame = data['frame']\n",
    "                frame = frame.to(self.device)\n",
    "                loss = self.forward(frame)\n",
    "                test_loss += loss.item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('Test loss: {:.4f}'.format(test_loss))\n",
    "        return test_loss\n",
    "\n",
    "    def train_loop(self, loaders, epochs=100, test_freq=2, save_freq=10):\n",
    "        print(\"=\"*40)\n",
    "        print(\"Training: epochs\", self.epoch, \"to\", self.epoch+epochs-1)\n",
    "        print(\"Training set:\", len(loaders['train'].dataset))\n",
    "        print(\"Test set:\", len(loaders['test'].dataset))\n",
    "        print(\"=\"*40)\n",
    "        # For some number of epochs...\n",
    "        for epoch in range(self.epoch, self.epoch+epochs):\n",
    "            # Run through the training data and record a loss.\n",
    "            loss = self.train_epoch(loaders['train'])\n",
    "            self.loss['train'][epoch] = loss\n",
    "            #log loss to TB\n",
    "            self.writer.add_scalar(\"Loss/Train\", loss, self.epoch)\n",
    "            self.writer.flush()\n",
    "            # Run through the test data and record a loss.\n",
    "            if (test_freq is not None) and (epoch % test_freq == 0):\n",
    "                loss = self.test_epoch(loaders['test'])\n",
    "                self.loss['test'][epoch] = loss\n",
    "            # Save the model.\n",
    "            if (save_freq is not None) and (epoch % save_freq == 0) and (epoch > 0):\n",
    "                filename = \"checkpoint_\"+str(epoch).zfill(3)+'.tar'\n",
    "                self.save_state(filename)\n",
    "\n",
    "    def save_state(self, filename):\n",
    "        \"\"\"Save all the model parameters to the given file.\"\"\"\n",
    "        layers = self._get_layers()\n",
    "        state = {}\n",
    "        for layer_name in layers:\n",
    "            state[layer_name] = layers[layer_name].state_dict()\n",
    "        state['optimizer_state'] = self.optimizer.state_dict()\n",
    "        state['loss'] = self.loss\n",
    "        state['z_dim'] = self.z_dim\n",
    "        state['epoch'] = self.epoch\n",
    "        state['lr'] = self.lr\n",
    "        state['save_dir'] = self.save_dir\n",
    "        filename = os.path.join(self.save_dir, filename)\n",
    "        torch.save(state, filename)\n",
    "\n",
    "    def load_state(self, filename):\n",
    "        checkpoint = torch.load(filename, map_location=self.device)\n",
    "        assert checkpoint['z_dim'] == self.z_dim\n",
    "        layers = self._get_layers()\n",
    "        for layer_name in layers:\n",
    "            layer = layers[layer_name]\n",
    "            layer.load_state_dict(checkpoint[layer_name])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        self.loss = checkpoint['loss']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "\n",
    "    def get_latent_umap(self, loaders, save_dir, title=None):\n",
    "        filename = str(self.epoch).zfill(3) + '_latents.pdf'\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "        latent = np.zeros((len(loaders['test'].dataset), self.z_dim)) #am using test loader b/c it is unshuffled.\n",
    "        with torch.no_grad():\n",
    "            j = 0\n",
    "            for i, sample in enumerate(loaders['test']):\n",
    "                x = sample['frame']\n",
    "                x = x.to(self.device)\n",
    "                mu, _, _ = self.encode(x)\n",
    "                latent[j:j+len(mu)] = mu.detach().cpu().numpy()\n",
    "                j += len(mu)\n",
    "        # UMAP these\n",
    "        transform = UMAP(n_components=2, n_neighbors=20, min_dist=0.1, \\\n",
    "        metric='euclidean', random_state=42)\n",
    "        projection = transform.fit_transform(latent)\n",
    "        # save these to do PCA and the rest\n",
    "        latent_info = {'latents':latent, 'UMAP':projection}\n",
    "        fname = os.path.join(self.save_dir, 'latent_info.tar')\n",
    "        torch.save(latent_info, fname)\n",
    "        #and return projections for plotting \n",
    "        return projection\n",
    "\n",
    "    def log_reconstruction(self, frames, batch_size, log_type):\n",
    "        frames = frames.reshape((batch_size, X_SHAPE[0], X_SHAPE[1], X_SHAPE[2]))\n",
    "        for i in range(batch_size):\n",
    "            frame = frames[i, :, :, 15]\n",
    "            fig_name = 'reconstruction_{}/{}'.format(log_type, i)\n",
    "            self.writer.add_image(fig_name, frame, dataformats='HW')\n",
    "\n",
    "    def get_recons(self, dataset, vals_list):\n",
    "        \"\"\"\n",
    "        Returns a np array with recons for all frames in train set (in order).\n",
    "        Useful when wanting to build tooltip plot.\n",
    "        Args:\n",
    "        ---------\n",
    "        Dataset: dataclass instance.\n",
    "        Vals_list: (list). First element is starting frame (inclusive) and\n",
    "        last is ending frame (exclusive).\n",
    "        \"\"\"\n",
    "        start = vals_list[0]\n",
    "        end = vals_list[1]\n",
    "        all_recons = []\n",
    "        for i in range(start, end):\n",
    "            frame = dataset.__getitem__(i)\n",
    "            frame = frame['frame'].unsqueeze(0).to(self.device)\n",
    "            _, _, recon = self.forward(frame, return_latent_rec=True)\n",
    "            all_recons.append(np.squeeze(recon))\n",
    "        return np.array(all_recons)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-luther",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-charger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
