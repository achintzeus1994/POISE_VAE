{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anticipated-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vanilla VAE implementation for Wfield Data.\n",
    "This uses a 3D encoder/decoder structure.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import os\n",
    "import datetime\n",
    "import itertools\n",
    "from umap import UMAP\n",
    "import torch\n",
    "from torch.distributions import LowRankMultivariateNormal\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "SUMMARY_WRITER_PATH = \"/home/achint/Practice_code/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_SHAPE = (7, 2, 540, 640)\n",
    "X_DIM = np.prod(X_SHAPE)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, save_dir='', lr=1e-3, z_dim=32, model_precision=10, device_name=\"auto\"):\n",
    "        super(VAE, self).__init__()\n",
    "        print('vae_here')\n",
    "        self.save_dir = save_dir\n",
    "        self.lr = lr\n",
    "        self.z_dim = z_dim\n",
    "        self.model_precision = model_precision\n",
    "        assert device_name != \"cuda\" or torch.cuda.is_available()\n",
    "        if device_name == \"auto\":\n",
    "            device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            self.device = torch.device(device_name)\n",
    "        if self.save_dir != '' and not os.path.exists(self.save_dir):\n",
    "            os.makedirs(self.save_dir)\n",
    "        self._build_network()\n",
    "        self.optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "        self.epoch = 0\n",
    "        self.loss = {'train':{}, 'test':{}}\n",
    "        #init summary writter instance for TB logging\n",
    "        #ts = datetime.datetime.now().date()\n",
    "        #self.writer = SummaryWriter(log_dir = os.path.join(self.save_dir, 'run', ts.strftime('%m_%d_%Y')))\n",
    "        self.writer = SummaryWriter(log_dir = SUMMARY_WRITER_PATH)\n",
    "        print('vae_here1')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _build_network(self):\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv3d(7,16,3,5,padding=1)\n",
    "        self.conv2 = nn.Conv3d(16,16,3,3,padding=1)\n",
    "        self.conv3 = nn.Conv3d(16,24,3,1,padding=1)\n",
    "        self.conv4 = nn.Conv3d(24,24,3,3,padding=1)\n",
    "        self.conv5 = nn.Conv3d(24,32,3,3,padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(7)\n",
    "        self.bn2 = nn.BatchNorm3d(16)\n",
    "        self.bn3 = nn.BatchNorm3d(16)\n",
    "        self.bn4 = nn.BatchNorm3d(24)\n",
    "        self.bn5 = nn.BatchNorm3d(24)\n",
    "        self.fc1 = nn.Linear(640, 256)\n",
    "        self.fc21 = nn.Linear(256, 64)\n",
    "        self.fc22 = nn.Linear(256, 64)\n",
    "        self.fc23 = nn.Linear(256, 64)\n",
    "        self.fc31 = nn.Linear(64, self.z_dim)\n",
    "        self.fc32 = nn.Linear(64, self.z_dim)\n",
    "        self.fc33 = nn.Linear(64, self.z_dim)\n",
    "        #Decoder\n",
    "        self.fc4 = nn.Linear(self.z_dim,64)\n",
    "        self.fc5 = nn.Linear(64,256)\n",
    "        self.fc6 = nn.Linear(256,640)\n",
    "        self.convt1 = nn.ConvTranspose3d(32,24,3,3,padding=1, output_padding=(0, 2, 2))\n",
    "        self.convt2 = nn.ConvTranspose3d(24,24,3,3,padding=1, output_padding=(0, 2, 0))\n",
    "        self.convt3 = nn.ConvTranspose3d(24,16,3,1,padding=1)\n",
    "        self.convt4 = nn.ConvTranspose3d(16,16,3,3,padding=1, output_padding=(0, 2, 1))\n",
    "        self.convt5 = nn.ConvTranspose3d(16,7,3,5,padding=1, output_padding=(1, 4, 4))\n",
    "        self.bn6 = nn.BatchNorm3d(32)\n",
    "        self.bn7 = nn.BatchNorm3d(24)\n",
    "        self.bn8 = nn.BatchNorm3d(24)\n",
    "        self.bn9 = nn.BatchNorm3d(16)\n",
    "        self.bn10 = nn.BatchNorm3d(16)\n",
    "\n",
    "    def _get_layers(self):\n",
    "        \"\"\"Return a dictionary mapping names to network layers.\"\"\"\n",
    "        return {'fc1':self.fc1, 'fc21':self.fc21, 'fc22':self.fc22,\n",
    "                'fc23':self.fc23,'fc31':self.fc31,'fc32':self.fc32,\n",
    "                'fc33':self.fc33, 'fc4':self.fc4, 'fc5':self.fc5,\n",
    "                'fc6':self.fc6,'bn1':self.bn1, 'bn2':self.bn2,\n",
    "                'bn3':self.bn3, 'bn4':self.bn4, 'bn5':self.bn5,\n",
    "                'bn6':self.bn6, 'bn7':self.bn7, 'bn8':self.bn8,\n",
    "                'bn9':self.bn9, 'bn10':self.bn10,'conv1':self.conv1,\n",
    "                'conv2':self.conv2, 'conv3':self.conv3,'conv4':self.conv4,\n",
    "                'conv5':self.conv5, 'convt1':self.convt1,'convt2':self.convt2,\n",
    "                'convt3':self.convt3, 'convt4':self.convt4,'convt5':self.convt5}\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.conv1(self.bn1(x)))\n",
    "        x = F.relu(self.conv2(self.bn2(x)))\n",
    "        x = F.relu(self.conv3(self.bn3(x)))\n",
    "        x = F.relu(self.conv4(self.bn4(x)))\n",
    "        x = F.relu(self.conv5(self.bn5(x)))\n",
    "        x = x.view(-1, 640)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        mu = F.relu(self.fc21(x))\n",
    "        mu = self.fc31(mu)\n",
    "        u = F.relu(self.fc22(x))\n",
    "        u = self.fc32(u).unsqueeze(-1) # Last dimension is rank \\Sigma = 1.\n",
    "        d = F.relu(self.fc23(x))\n",
    "        d = torch.exp(self.fc33(d)) # d must be positive.\n",
    "        return mu, u, d\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = F.relu(self.fc4(z))\n",
    "        z = F.relu(self.fc5(z))\n",
    "        z = F.relu(self.fc6(z))\n",
    "        z = z.view(-1,32,1,4,5)\n",
    "        z = F.relu(self.convt1(self.bn6(z)))\n",
    "        z = F.relu(self.convt2(self.bn7(z)))\n",
    "        z = F.relu(self.convt3(self.bn8(z)))\n",
    "        z = F.relu(self.convt4(self.bn9(z)))\n",
    "        z = F.relu(self.convt5(self.bn10(z)))\n",
    "        z = z.view(-1, X_DIM)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, return_latent_rec=False, train_mode=False):\n",
    "        mu, u, d = self.encode(x)\n",
    "        latent_dist = LowRankMultivariateNormal(mu, u, d)\n",
    "        z = latent_dist.rsample()\n",
    "        x_rec = self.decode(z)\n",
    "        if train_mode:\n",
    "            batch_size = x_rec.detach().cpu().numpy().shape[0]\n",
    "            self.log_reconstruction(x_rec.detach().cpu().numpy(), batch_size, log_type='train')\n",
    "        # E_{q(z|x)} p(z)\n",
    "        elbo = -0.5 * (torch.sum(torch.pow(z,2)) + self.z_dim * np.log(2*np.pi))\n",
    "        # E_{q(z|x)} p(x|z)\n",
    "        pxz_term = -0.5 * X_DIM * (np.log(2*np.pi/self.model_precision))\n",
    "        l2s = torch.sum(torch.pow(x.view(x.shape[0],-1) - x_rec, 2), dim=1)\n",
    "        pxz_term = pxz_term - 0.5 * self.model_precision * torch.sum(l2s)\n",
    "        elbo = elbo + pxz_term\n",
    "        # H[q(z|x)]\n",
    "        elbo = elbo + torch.sum(latent_dist.entropy())\n",
    "        if return_latent_rec:\n",
    "            return -elbo, z.detach().cpu().numpy(), \\\n",
    "            x_rec.view(-1, X_SHAPE[0], X_SHAPE[1], X_SHAPE[2], X_SHAPE[3]).detach().cpu().numpy()\n",
    "        return -elbo\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        self.train()\n",
    "        train_loss = 0.0\n",
    "        print('reaching here')\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            print('batch_idx',batch_idx)\n",
    "            self.optimizer.zero_grad()\n",
    "            frame = data['frame']\n",
    "            frame = frame.to(self.device)\n",
    "            loss = self.forward(frame, train_mode=True)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        print('Epoch: {} Average loss: {:.4f}'.format(self.epoch, \\\n",
    "        train_loss))\n",
    "        self.epoch += 1\n",
    "        return train_loss\n",
    "\n",
    "    def test_epoch(self, test_loader):\n",
    "        self.eval()\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_loader):\n",
    "                frame = data['frame']\n",
    "                frame = frame.to(self.device)\n",
    "                loss = self.forward(frame)\n",
    "                test_loss += loss.item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('Test loss: {:.4f}'.format(test_loss))\n",
    "        return test_loss\n",
    "\n",
    "    def train_loop(self, loaders, epochs=100, test_freq=2, save_freq=10):\n",
    "        print(\"=\"*40)\n",
    "        print(\"Training: epochs\", self.epoch, \"to\", self.epoch+epochs-1)\n",
    "        print(\"Training set:\", len(loaders['train'].dataset))\n",
    "        print(\"Test set:\", len(loaders['test'].dataset))\n",
    "        print(\"=\"*40)\n",
    "        # For some number of epochs...\n",
    "        for epoch in range(self.epoch, self.epoch+epochs):\n",
    "            # Run through the training data and record a loss.\n",
    "            loss = self.train_epoch(loaders['train'])\n",
    "            self.loss['train'][epoch] = loss\n",
    "            #log loss to TB\n",
    "            self.writer.add_scalar(\"Loss/Train\", loss, self.epoch)\n",
    "            self.writer.flush()\n",
    "            # Run through the test data and record a loss.\n",
    "            if (test_freq is not None) and (epoch % test_freq == 0):\n",
    "                loss = self.test_epoch(loaders['test'])\n",
    "                self.loss['test'][epoch] = loss\n",
    "            # Save the model.\n",
    "            if (save_freq is not None) and (epoch % save_freq == 0) and (epoch > 0):\n",
    "                filename = \"checkpoint_\"+str(epoch).zfill(3)+'.tar'\n",
    "                self.save_state(filename)\n",
    "\n",
    "    def save_state(self, filename):\n",
    "        \"\"\"Save all the model parameters to the given file.\"\"\"\n",
    "        layers = self._get_layers()\n",
    "        state = {}\n",
    "        for layer_name in layers:\n",
    "            state[layer_name] = layers[layer_name].state_dict()\n",
    "        state['optimizer_state'] = self.optimizer.state_dict()\n",
    "        state['loss'] = self.loss\n",
    "        state['z_dim'] = self.z_dim\n",
    "        state['epoch'] = self.epoch\n",
    "        state['lr'] = self.lr\n",
    "        state['save_dir'] = self.save_dir\n",
    "        filename = os.path.join(self.save_dir, filename)\n",
    "        torch.save(state, filename)\n",
    "\n",
    "    def load_state(self, filename):\n",
    "        checkpoint = torch.load(filename, map_location=self.device)\n",
    "        assert checkpoint['z_dim'] == self.z_dim\n",
    "        layers = self._get_layers()\n",
    "        for layer_name in layers:\n",
    "            layer = layers[layer_name]\n",
    "            layer.load_state_dict(checkpoint[layer_name])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        self.loss = checkpoint['loss']\n",
    "        self.epoch = checkpoint['epoch']\n",
    "\n",
    "    def get_latent_umap(self, loaders, save_dir, title=None):\n",
    "        filename = str(self.epoch).zfill(3) + '_latents.pdf'\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "        latent = np.zeros((len(loaders['test'].dataset), self.z_dim)) #take data unshuffled\n",
    "        with torch.no_grad():\n",
    "            j = 0\n",
    "            for i, sample in enumerate(loaders['test']):\n",
    "                x = sample['frame']\n",
    "                x = x.to(self.device)\n",
    "                mu, _, _ = self.encode(x)\n",
    "                latent[j:j+len(mu)] = mu.detach().cpu().numpy()\n",
    "                j += len(mu)\n",
    "        # UMAP these\n",
    "        transform = UMAP(n_components=2, n_neighbors=20, min_dist=0.1, \\\n",
    "        metric='euclidean', random_state=42)\n",
    "        projection = transform.fit_transform(latent)\n",
    "        # save these to do PCA and the rest\n",
    "        latent_info = {'latents':latent, 'UMAP':projection}\n",
    "        fname = os.path.join(self.save_dir, 'latent_info.tar')\n",
    "        torch.save(latent_info, fname)\n",
    "        #return projection\n",
    "\n",
    "    def log_reconstruction(self, frames, batch_size, log_type):\n",
    "        frames = frames.reshape((batch_size, X_SHAPE[0], X_SHAPE[1], X_SHAPE[2], X_SHAPE[3]))\n",
    "        #log only some elements in batch...\n",
    "        all_batch_items = list(range(batch_size))\n",
    "        random_subset = random.sample(all_batch_items, 5)\n",
    "        for i in random_subset:\n",
    "            ch1_frame = frames[i, 4, 0, :, :]\n",
    "            ch2_frame = frames[i, 4, 1, :, :]\n",
    "            ch1_fig_name = 'reconstruction_{}/{}_ch1'.format(log_type, i)\n",
    "            ch2_fig_name = 'reconstruction_{}/{}_ch2'.format(log_type, i)\n",
    "            self.writer.add_image(ch1_fig_name, ch1_frame, dataformats='HW')\n",
    "            self.writer.add_image(ch2_fig_name, ch2_frame, dataformats='HW')\n",
    "\n",
    "    def get_recons(self, dataset, vals_list):\n",
    "        \"\"\"\n",
    "        Returns a np array with recons for all frames in train set (in order).\n",
    "        Useful when wanting to build tooltip plot.\n",
    "        Args:\n",
    "        ---------\n",
    "        Dataset: dataclass instance.\n",
    "        Vals_list: (list). First element is starting frame (inclusive) and\n",
    "        last is ending frame (exclusive).\n",
    "        \"\"\"\n",
    "        start = vals_list[0]\n",
    "        end = vals_list[1]\n",
    "        all_recons = []\n",
    "        for i in range(start, end):\n",
    "            frame = dataset.__getitem__(i)\n",
    "            frame = frame['frame'].unsqueeze(0).to(self.device)\n",
    "            _, _, recon = self.forward(frame, return_latent_rec=True)\n",
    "            all_recons.append(np.squeeze(recon))\n",
    "        return np.array(all_recons)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-testament",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
