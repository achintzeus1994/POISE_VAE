{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "permanent-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script defining WfieldDataSet Class and loaders to be used along with VAE model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from wfield import * #for loading wfield data in nice format\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "changing-fitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WfieldDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Defines WfieldDataSet to be used with VAE model.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, transform=None):\n",
    "        #use wfield to create a memory map version of entire data\n",
    "        print('Dataclass_here')\n",
    "        data = mmap_dat(file_path)\n",
    "        print('Dataclass_here1',np.shape(data))\n",
    "        print('Dataclass_here1',np.shape(data[0:100]))\n",
    "        #data = data[0:100]\n",
    "        self.df = data\n",
    "        \n",
    "#         self.max = np.amax(data)\n",
    "#         self.min = np.amin(data)\n",
    "#         self.mean = np.mean(data)             \n",
    "        self.max = np.max(data)\n",
    "        self.min = np.min(data)\n",
    "        self.mean = np.mean(data)\n",
    "\n",
    "#.      self.max = np.max(data)\n",
    "        self.transform = transform\n",
    "        print('Dataclass_here6')\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns number of samples in dset.\n",
    "        \"\"\"\n",
    "        return (int(self.df.shape[0] - 7))\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sample from dset.\n",
    "        \"\"\"\n",
    "        time_start = idx\n",
    "        time_end = time_start + 7\n",
    "        frame = self.df[time_start:time_end, :, :, :]\n",
    "        scld_frame = np.true_divide((frame - self.min), (self.max - self.min)) #min/max norm (global)\n",
    "        sample = {'frame': scld_frame}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Converts sample arrays to tensor which can be directly fed to model\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        frame = sample['frame']\n",
    "        return {'frame':torch.from_numpy(frame).float()}\n",
    "\n",
    "def setup_data_loaders(batch_size=32, shuffle=(True, False), file_path=''):\n",
    "    #for now am not worried about train/test splitting\n",
    "    print('Dataclass_here3')\n",
    "    dset = WfieldDataSet(file_path=file_path, transform = ToTensor())\n",
    "    print('Dataclass_here4')\n",
    "    train_loader = DataLoader(dset, batch_size=batch_size, \\\n",
    "    shuffle=shuffle[0], num_workers = 0)\n",
    "    test_loader = DataLoader(dset, batch_size=batch_size, \\\n",
    "    shuffle=shuffle[1], num_workers=0)\n",
    "    print('Dataclass_here5')\n",
    "    return{'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-serve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
