{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "underlying-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script defining EvilMouDataSet Class and loaders to be used along with VAE model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import h5py\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvilMouDataSet(Dataset):\n",
    "    \"\"\"\n",
    "    Defines EvilMouDataSet to be used with VAE model.\n",
    "    This is NOT efficient at all in terms of mem usage.\n",
    "    You might wish to do something like having your dset be list of .h5 files\n",
    "    And then in the __getitem__ method pick only file and corresponding slices you want.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        #collect all file names for files containing different frames\n",
    "        all_frames = []\n",
    "        for frame in Path(data_dir).rglob('frame*.h5'):\n",
    "            all_frames.append(str(frame))\n",
    "        #get first set of frames\n",
    "        #load them\n",
    "        f0 = h5py.File(all_frames[0], 'r+')\n",
    "        all_data = f0['cam1'][:]\n",
    "        #now read in rest of them and concatenate them over last axis\n",
    "        #this should give an array with all frames in dset (160, 120, 89900)\n",
    "        for i in range(1, len(all_frames)):\n",
    "            f = h5py.File(all_frames[i], 'r+')\n",
    "            f_data = f['cam1'][:]\n",
    "            all_data = np.concatenate((all_data, f_data), axis=2)\n",
    "        self.df = all_data\n",
    "        self.max = np.amax(all_data.flatten())\n",
    "        self.min = np.amin(all_data.flatten())\n",
    "        self.mean = np.mean(all_data.flatten())\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns number of samples in dset\n",
    "        \"\"\"\n",
    "        return (int(self.df.shape[2] - 31))\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sample from dset.\n",
    "        \"\"\"\n",
    "        time_start = idx\n",
    "        time_end = time_start + 31 #am picking 31 frames at time here, this might be too much for your data!\n",
    "        frame = self.df[:, :, time_start:time_end]\n",
    "        scld_frame = np.true_divide((frame - self.min), (self.max - self.min)) #min/max norm (global)\n",
    "        sample = {'frame': scld_frame}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "    Converts sample arrays to tensor which can be directly fed to model\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        frame = sample['frame']\n",
    "        return {'frame':torch.from_numpy(frame).float()}\n",
    "\n",
    "def setup_data_loaders(batch_size=64, shuffle=(True, False), data_dir=''):\n",
    "    #for now am not worried about train/test splitting\n",
    "    #like we talked, these are not as useful for model eval as in supervised settings\n",
    "    dset = EvilMouDataSet(data_dir=data_dir, transform = ToTensor())\n",
    "    train_loader = DataLoader(dset, batch_size=batch_size, \\\n",
    "    shuffle=shuffle[0], num_workers = 0)\n",
    "    test_loader = DataLoader(dset, batch_size=batch_size, \\\n",
    "    shuffle=shuffle[1], num_workers=0)\n",
    "    return{'train':train_loader, 'test':test_loader, 'dset':dset}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
