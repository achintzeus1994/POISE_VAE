{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alpine-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "## hello "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-wallet",
   "metadata": {},
   "source": [
    "To sample from the prior we consider its conditional distributions,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    p(z|z')&\\sim \\mathrm{exp}\\left(-(1-g_{22}z'^2)z^2+(g_{11}z'\\right) \\\\\n",
    "    p(z'|z)&\\sim \\mathrm{exp}\\left(-(1-g_{22}z^2) {z'}^2+(g_{11}z\\right)\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The variance and mean of p(z|z') is given by,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma^2&=\\frac{1}{2(1-g_{22}z'^2)}\\\\\n",
    "    \\mu &=\\sigma^2*(g_{11}z')\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The variance and mean of p(z'|z) is given by,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma'^2&=\\frac{1}{2(1-g_{22}z^2)}\\\\\n",
    "    \\mu' &=\\sigma'^2*(g_{11}z)\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "To implement Gibbs sampling on prior, define the following functions:\n",
    "* var_calc_prior:\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\mathrm{Input}&:  z\\, (\\mathrm{or}\\, z'),  g_{22} \\\\\n",
    "    \\mathrm{Output}&: \\sigma^2\\, (\\mathrm{or}\\, \\sigma'^2)\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "* mean_calc_prior:  \n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\mathrm{Input}&: z\\, (\\mathrm{or}\\, z'), \\sigma^2\\, (\\mathrm{or}\\, \\sigma'^2), g_{11},  g_{22}\\\\\n",
    "    \\mathrm{Output}&: \\mu\\,(\\mathrm{or}\\, \\mu')\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The algorithm is as follows:\n",
    "* Initialize z and z'\n",
    "* Iterate 5 times and on each iteration calculate\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma^2&= \\mathrm{var\\_calc\\_prior}(z',g_{22})\\\\\n",
    "    \\mu   &= \\mathrm{mu\\_calc\\_prior}(z',\\sigma^2, g_{11},  g_{22})\\\\\n",
    "    z    &= \\mu+\\sqrt{\\sigma^2}\\odot \\epsilon\\\\\n",
    "    \\sigma'^2&= \\mathrm{var\\_calc\\_prior}(z,g_{22})\\\\\n",
    "    \\mu'   &= \\mathrm{mu\\_calc\\_prior}(z,\\sigma'^2, g_{11},  g_{22})\\\\\n",
    "    z' &= \\mu'+\\sqrt{\\sigma'^2}\\odot \\epsilon\n",
    "    \\end{aligned}\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gibbs_sampler():\n",
    "    def __init__(self,latent_dim1, latent_dim2, batch_size):\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def var_calc(self,z,g22,lambda_2):\n",
    "        val   = 2*(1-torch.matmul(torch.square(z),g22)-lambda_2)\n",
    "        return torch.reciprocal(val)\n",
    "    def mean_calc(self,z,var,g11,lambda_1):\n",
    "        beta = torch.matmul(z,g11)+lambda_1\n",
    "        return var*beta\n",
    "    \n",
    "    def value_calc(self,z,g11,g22,lambda_1,lambda_2):\n",
    "        var1          = self.var_calc(z,g22,lambda_2)\n",
    "        mean1         = self.mean_calc(z,var1,g11,lambda_1)\n",
    "        out           = mean1+torch.sqrt(var1.float())*torch.randn_like(var1)\n",
    "        return out \n",
    "    \n",
    "    def gibbs_sample(self,flag,z1,z2,g11,g22,lambda_1,lambda_2,lambdap_1,lambdap_2,n_iterations, return_mean_and_variance=False):\n",
    "        if return_mean_and_variance:\n",
    "            # return whatever\n",
    "            # TODO\n",
    "        else:\n",
    "            if flag == 1:\n",
    "                z1 = torch.randn(self.batch_size,self.latent_dim1).to(device)       ## \n",
    "                z2 = torch.randn(self.batch_size,self.latent_dim2).to(device)       ## For estimating z' in  q(z'|z,x)\n",
    "\n",
    "            for i in range(n_iterations):\n",
    "                z1  = self.value_calc(z2,torch.transpose(g11,0,1),torch.transpose(g22,0,1),lambda_1,lambda_2) \n",
    "                z2  = self.value_calc(z1,g11,g22,lambdap_1,lambdap_2) \n",
    "\n",
    "            return z1,z2       \n",
    "    \n",
    "\"\"\"\n",
    "Size of z1:        [batch_size, latent_dim1]\n",
    "Size of z2:        [batch_size, latent_dim1]\n",
    "Size of g11:       [latent_dim1, latent_dim2]\n",
    "Size of g22:       [latent_dim1, latent_dim2]\n",
    "Size of lambda_1:  [batch_size, latent_dim1]\n",
    "Size of lambda_2:  [batch_size, latent_dim1]\n",
    "Size of lambdap_1: [batch_size, latent_dim2]\n",
    "Size of lambdap_2: [batch_size, latent_dim2]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-highway",
   "metadata": {},
   "source": [
    "To sample from the posterior we consider its conditional distributions,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    q(z|z',x)&\\sim \\mathrm{exp}\\left(-(1-g_{22}z'^2-\\lambda_2(x))z^2+(g_{11}z'+\\lambda_1(x))z\\right) \\\\\n",
    "    q(z'|z,x')&\\sim \\mathrm{exp}\\left(-(1-g_{22}z^2 -\\lambda'_2(x')) {z'}^2+(g_{11}z+\\lambda'_1(x')){z'}\\right)\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The variance and mean of q(z|z',x) is given by,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma^2&=\\frac{1}{2(1-g_{22}z'^2-\\lambda_2(x))}\\\\\n",
    "    \\mu &=\\sigma^2*(g_{11}z'+\\lambda_1(x))\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The variance and mean of q(z'|z,x') is given by,\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma'^2&=\\frac{1}{2(1-g_{22}z^2-\\lambda'_2(x'))}\\\\\n",
    "    \\mu' &=\\sigma'^2*(g_{11}z+\\lambda'_1(x'))\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "To implement Gibbs sampling on posterior, define the following functions:\n",
    "* var_calc_posterior:\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\mathrm{Input}&:  z\\, (\\mathrm{or}\\, z'), g_{22}, \\lambda_2(x) (\\mathrm{or}\\, \\lambda'_2(x')) \\\\\n",
    "    \\mathrm{Output}&: \\sigma^2\\, (\\mathrm{or}\\, \\sigma'^2)\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "* mean_calc_posterior:  \n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\mathrm{Input}&: z\\, (\\mathrm{or}\\, z'), \\sigma^2\\, (\\mathrm{or}\\, \\sigma'^2), g_{11}, g_{22},\\lambda_1(x) (\\mathrm{or}\\, \\lambda'_1(x'))\\\\\n",
    "    \\mathrm{Output}&: \\mu\\,(\\mathrm{or}\\, \\mu')\n",
    "    \\end{aligned}\n",
    "</span>\n",
    "The algorithm is as follows:\n",
    "* Initialize z and z'\n",
    "* Iterate 5 times and on each iteration calculate\n",
    "<span class=\"math display\">\n",
    "    \\begin{aligned}\n",
    "    \\sigma^2&= \\mathrm{var\\_calc\\_posterior}(z',g_{22},\\lambda_2(x))\\\\\n",
    "    \\mu   &= \\mathrm{mu\\_calc\\_posterior}(z',\\sigma^2, g_{11},  g_{22},\\lambda_1(x))\\\\\n",
    "    z    &= \\mu+\\sqrt{\\sigma^2}\\odot \\epsilon\\\\\n",
    "    \\sigma'^2&= \\mathrm{var\\_calc\\_posterior}(z,g_{22},\\lambda'_2(x'))\\\\\n",
    "    \\mu'   &= \\mathrm{mu\\_calc\\_posterior}(z,\\sigma'^2, g_{11},  g_{22},\\lambda'_2(x'))\\\\\n",
    "    z' &= \\mu'+\\sqrt{\\sigma'^2}\\odot \\epsilon\n",
    "    \\end{aligned}\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-center",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
