{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from gibbs_sampler_poise.ipynb\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d3781954604a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/achint/Practice_code/Synthetic_dataset/POISE_VAE_even_odd_MNIST/untitled_regularized.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mneural_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_MNIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mneural_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import import_ipynb\n",
    "import gibbs_sampler_poise\n",
    "import torch\n",
    "latent_dim1 = 32\n",
    "latent_dim2 = 16\n",
    "batch_size = 1\n",
    "dim_MNIST   = 784\n",
    "from torch.nn import functional as F  #for the activation function\n",
    "PATH = \"/home/achint/Practice_code/Synthetic_dataset/POISE_VAE_even_odd_MNIST/untitled_regularized.txt\"\n",
    "state = torch.load(PATH)\n",
    "neural_net = model(latent_dim1, latent_dim2, batch_size,dim_MNIST).to(device)\n",
    "\n",
    "neural_net.load_state_dict(state['state_dict'])\n",
    "neural_net.eval()\n",
    "LATENT_TRAVERSAL_PATH = \"/home/achint/Practice_code/Synthetic_dataset/POISE_VAE_even_odd_MNIST/reconstructions_experiment/latent_traversal/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interpreted-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class latent_traversals():\n",
    "    def __init__(self,latent_dim1, latent_dim2, batch_size,dim_MNIST):\n",
    "        super(latent_traversals,self).__init__()\n",
    "        self.latent_dim1 = latent_dim1\n",
    "        self.latent_dim2 = latent_dim2\n",
    "        self.batch_size = batch_size\n",
    "        self.gibbs      = gibbs_sampler_poise.gibbs_sampler(self.latent_dim1, self.latent_dim2, self.batch_size) \n",
    "    def traversals(self,flag_initialize,z1,z2,g11,g22,mu1,var1,mu2,var2,n_iterations):\n",
    "        \n",
    "        z1_posterior,z2_posterior,mean1,var1,mean2,var2 = self.gibbs.gibbs_sample(flag_initialize,z1,\n",
    "                                                                                  z2,\n",
    "                                                                                  g11,\n",
    "                                                                                  g22,\n",
    "                                                                                  mu1,\n",
    "                                                                                  var1,\n",
    "                                                                                  mu2,\n",
    "                                                                                  var2,\n",
    "                                                                                  n_iterations)\n",
    "#         for i in range(latent_dim1+latent_dim2):\n",
    "#             if i<=latent_dim1:\n",
    "        j = 1\n",
    "        z1_perturbed = z1_posterior\n",
    "        z2_perturbed = z2_posterior        \n",
    "        z1_perturbed[0]= mean1[0]+j*var1[0]\n",
    "        z2_perturbed[0]= mean2[0]+j*var2[0]\n",
    "        reconstruction1, reconstruction2 = model_decoder(z1_perturbed,z2_perturbed)\n",
    "        return reconstruction1,reconstruction2\n",
    "    def model_decoder(z1_perturbed,z2_perturbed):\n",
    "        # decoding for MNIST1\n",
    "        x1 = F.relu(set1_dec1(z1_perturbed))\n",
    "        x1 = set1_dec2(x1)\n",
    "        # decoding for MNIST2\n",
    "        x2 = F.relu(set2_dec1(z2_perturbed))\n",
    "        x2 = set2_dec2(x2)\n",
    "        reconstruction1 = set1_dec3(x1)\n",
    "        reconstruction2 = set2_dec3(x2)\n",
    "        return reconstruction1, reconstruction2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-bible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "smart-colombia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latent_traversals(\n",
       "  (set1_enc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (set1_enc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (set1_enc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (set2_enc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (set2_enc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (set2_enc3): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (set1_dec1): Linear(in_features=32, out_features=128, bias=True)\n",
       "  (set1_dec2): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (set1_dec3): Linear(in_features=512, out_features=784, bias=True)\n",
       "  (set2_dec1): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (set2_dec2): Linear(in_features=128, out_features=512, bias=True)\n",
       "  (set2_dec3): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-namibia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
