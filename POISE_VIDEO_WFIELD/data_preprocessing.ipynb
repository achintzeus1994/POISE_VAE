{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "better-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script defining EvilMouDataSet Class and loaders to be used along with VAE model.\n",
    "\"\"\"\n",
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import glob\n",
    "from wfield import * #for loading wfield data in nice format\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvilMouDataSet(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Defines EvilMouDataSet to be used with VAE model.\n",
    "    This is NOT efficient at all in terms of mem usage.\n",
    "    You might wish to do something like having your dset be list of .h5 files\n",
    "    And then in the __getitem__ method pick only file and corresponding slices you want.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_dir, wfield_dir, transform=None):\n",
    "        #collect all file names for files containing different frames\n",
    "        all_frames = []\n",
    "        for frame in Path(video_dir).rglob('frame*.h5'):\n",
    "            all_frames.append(str(frame))\n",
    "        #get first set of frames\n",
    "        #load them\n",
    "        f0 = h5py.File(all_frames[0], 'r+')\n",
    "        all_data = f0['cam1'][:]\n",
    "        #now read in rest of them and concatenate them over last axis\n",
    "        #this should give an array with all frames in dset (160, 120, 89900)\n",
    "#         for i in range(1, len(all_frames)):\n",
    "#             f = h5py.File(all_frames[i], 'r+')\n",
    "#             f_data = f['cam1'][:]\n",
    "#             all_data = np.concatenate((all_data, f_data), axis=2)\n",
    "        self.df_video      = all_data\n",
    "        self.max_video     = np.amax(all_data.flatten())\n",
    "        self.min_video     = np.amin(all_data.flatten())\n",
    "        self.mean_video    = np.mean(all_data.flatten())\n",
    "        \n",
    "        wfield_data        = mmap_dat(wfield_dir)\n",
    "        wfield_data        = wfield_data[0:100]\n",
    "        self.df_wfield     = wfield_data\n",
    "        self.max_wfield    = np.max(wfield_data)\n",
    "        self.min_wfield    = np.min(wfield_data)\n",
    "        self.mean_wfield   = np.mean(wfield_data)\n",
    "        self.transform     = transform\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns number of samples in dset\n",
    "        \"\"\"\n",
    "        return (int(self.df_wfield.shape[0] - 7))\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sample from dset.\n",
    "        \"\"\"\n",
    "        time_start = idx\n",
    "        time_end = time_start + 7 #am picking 1 frames at time here, this might be too much for your data!\n",
    "        frame_video = self.df_video[:, :, time_start:time_end]\n",
    "        scld_frame_video = np.true_divide((frame_video - self.min_video), (self.max_video - self.min_video)) #min/max norm (global)\n",
    "        video_data   = torch.from_numpy(scld_frame_video)   # tensor of size [160, 120, 1]\n",
    "        video_data   = video_data[:,:,0]\n",
    "        \n",
    "        frame_wfield = self.df_wfield[time_start:time_end, :, :, :]\n",
    "        scld_frame_wfield = np.true_divide((frame_wfield - self.min_wfield), (self.max_wfield - self.min_wfield)) #min/max norm (global)\n",
    "        wfield_data  = torch.from_numpy(scld_frame_wfield)  # tensor of size [7, 2, 540, 640]\n",
    "        wfield_data  = wfield_data[0,:,:,:]\n",
    "        return video_data, wfield_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-unemployment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
