{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "structural-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Script defining EvilMouDataSet Class and loaders to be used along with VAE model.\n",
    "\"\"\"\n",
    "import os, sys\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import glob\n",
    "from wfield import * #for loading wfield data in nice format\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "# import pickle\n",
    "# import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sustainable-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvilMouDataSet(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Defines EvilMouDataSet to be used with VAE model.\n",
    "    This is NOT efficient at all in terms of mem usage.\n",
    "    You might wish to do something like having your dset be list of .h5 files\n",
    "    And then in the __getitem__ method pick only file and corresponding slices you want.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_dir, wfield_dir, transform=None):\n",
    "        all_data = np.load(video_dir)\n",
    "        self.df_video      = all_data\n",
    "        self.max_video     = np.amax(all_data.flatten())\n",
    "        self.min_video     = np.amin(all_data.flatten())\n",
    "        self.mean_video    = np.mean(all_data.flatten())\n",
    "        #wfield_data        = mmap_dat(wfield_dir) \n",
    "        wfield_data        = np.load(wfield_dir)        \n",
    "        self.df_wfield     = wfield_data\n",
    "        self.max_wfield    = np.max(wfield_data)\n",
    "        self.min_wfield    = np.min(wfield_data)\n",
    "        self.mean_wfield   = np.mean(wfield_data)\n",
    "        self.transform     = transform\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns number of samples in dset\n",
    "        \"\"\"\n",
    "        \n",
    "        return (int(self.df_wfield.shape[0]))\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a single sample from the two dsets.\n",
    "        \"\"\"\n",
    "        frame_video = self.df_video[:, :, idx]\n",
    "        scld_frame_video = np.true_divide((frame_video - self.min_video), (self.max_video - self.min_video)) #min/max norm (global)\n",
    "        video_data   = torch.from_numpy(scld_frame_video)   # tensor of size [160, 120]\n",
    "        frame_wfield = self.df_wfield[idx, :, :, :]\n",
    "        scld_frame_wfield = np.true_divide((frame_wfield - self.min_wfield), (self.max_wfield - self.min_wfield)) #min/max norm (global)\n",
    "        wfield_data  = torch.from_numpy(scld_frame_wfield)  # tensor of size [2, 540, 640]\n",
    "        return video_data, wfield_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "confused-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 10\n",
    "# VIDEO_PATH          = \"/hdd/achint_files/musall_behavior\"\n",
    "# WFIELD_PATH         = \"/hdd/achint_files/wfield_data/frames_2_540_640_uint16.dat\"\n",
    "\n",
    "\n",
    "# loaders_dict = EvilMouDataSet(video_dir=VIDEO_PATH,wfield_dir=WFIELD_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liberal-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WFIELD_TRAINING_PATH= \"/hdd/achint_files/musall_behavior/wfield_train_data.npy\"\n",
    "# wfield_data        = np.load(WFIELD_TRAINING_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-membership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import skimage.transform\n",
    "\n",
    "# i_width = 135\n",
    "# i_height = 160\n",
    "\n",
    "# train_wfield = skimage.transform.resize(wfield_data, (2,i_width,i_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regulated-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wfield import * #for loading wfield data in nice format\n",
    "# file_path=\"/hdd/achint_files/wfield_data/frames_2_540_640_uint16.dat\"\n",
    "# data = mmap_dat(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "english-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import skimage.transform \n",
    "# i_width = 135\n",
    "# i_height = 160\n",
    "# wfield_data =[]\n",
    "# for i in range(len(data[:,0,0])):\n",
    "#     resized_data= skimage.transform.resize(data[i], (2,i_width,i_height))\n",
    "#     wfield_data.append(resized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "backed-toner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39123, 2, 135, 160)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.shape(wfield_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stuck-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_training = int(0.8*len(data[:,0,0]))\n",
    "# wfield_data1=np.asarray(wfield_data) \n",
    "# training_data=(wfield_data1[:len_training,:,:,:])\n",
    "# np.save(\"/hdd/achint_files/wfield_data/DOWNSAMPLED_wfield_train_data\",training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "defined-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=(wfield_data1[len_training:,:,:,:])\n",
    "# np.save(\"/hdd/achint_files/wfield_data/DOWNSAMPLED_wfield_test_data\",test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "grateful-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traing=np.load(\"/hdd/achint_files/wfield_data/DOWNSAMPLED_wfield_train_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "needed-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31298, 2, 135, 160)\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(traing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alternate-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_training = int(0.8*len(data[:,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "killing-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31298"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "scheduled-transmission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31298, 2, 135, 160)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.shape(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "hybrid-grade",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ac87df4244a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlen_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwfield_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# len_training = len(data[:,0,0])\n",
    "# wfield_data[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "unavailable-cable",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n"
     ]
    }
   ],
   "source": [
    "# for i,joint_data in enumerate(loaders_dict):\n",
    "#         data1    = joint_data[0]\n",
    "#         data1    = data1.float()\n",
    "#         data2    = joint_data[1]\n",
    "#         data2    = data2.float()\n",
    "#         data1    = data1.to(device)\n",
    "#         data2    = data2.to(device)\n",
    "        \n",
    "        #data1    = torch.unsqueeze(data1,0)\n",
    "        #data2    = torch.unsqueeze(data2,0)\n",
    "#     if i == 5:\n",
    "#         print(data1.size())\n",
    "#         print(data2.size())\n",
    "#         data1    = data1.view(data1.size(0), -1)\n",
    "#         data2    = data2.view(data2.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-budget",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "satisfied-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = np.load(\"/hdd/achint_files/musall_behavior/video_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "legitimate-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data=np.float32(all_data[:,:,:len_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "approximate-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"/hdd/achint_files/musall_behavior/video_training_data\",training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "accessible-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data=np.float32(all_data[:,:,len_training:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "contained-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"/hdd/achint_files/musall_behavior/video_test_data\",test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "damaged-humanitarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "handed-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_training=int(0.8*len(all_data[0,0,:]))\n",
    "# len_test = len(all_data[0,0,:])-len_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unique-advancement",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39123, 2, 540, 640)\n"
     ]
    }
   ],
   "source": [
    "# WFIELD_PATH         = \"/hdd/achint_files/wfield_data/frames_2_540_640_uint16.dat\"\n",
    "# wfield_data        = mmap_dat(WFIELD_PATH)\n",
    "# print(np.shape(wfield_data) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "crazy-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data=(wfield_data[:len_training,:,:])\n",
    "# np.save(\"/hdd/achint_files/musall_behavior/wfield_train_data\",training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continental-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_training = int(0.8*len(wfield_data[:,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "medium-citizenship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31298"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_training = int(0.8*len(wfield_data[:,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "further-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31298, 2, 540, 640)\n"
     ]
    }
   ],
   "source": [
    "# print(np.shape(wfield_data[:len_training,:,:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cubic-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=(wfield_data[len_training:,:,:])\n",
    "# np.save(\"/hdd/achint_files/musall_behavior/wfield_test_data\",test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-blanket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
