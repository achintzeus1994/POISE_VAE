{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-round",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "martial-spoke",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "# \tpass\n",
    "#partition = get_syllable_partition(spec_dirs_both, split=1, max_num_files=2500)\n",
    "\n",
    "#loaders = get_syllable_data_loaders(partition, num_workers=num_workers)\n",
    "# A=['/hdd/achint_files/achint_mousedata/Tom Data/Group1/specs/syllables_0055.hdf5','/hdd/achint_files/achint_mousedata/Tom Data/Group1/specs/syllables_0056.hdf5','/hdd/achint_files/achint_mousedata/Tom Data/Group1/specs/syllables_0057.hdf5']\n",
    "# s=SyllableDataset(A,2)\n",
    "# s[5]\n",
    "\n",
    "\"\"\"\n",
    "A Variational Autoencoder (VAE) for spectrogram data.\n",
    "\n",
    "VAE References\n",
    "--------------\n",
    ".. [1] Kingma, Diederik P., and Max Welling. \"Auto-encoding variational bayes.\"\n",
    "\tarXiv preprint arXiv:1312.6114 (2013).\n",
    "\n",
    "\t`<https://arxiv.org/abs/1312.6114>`_\n",
    "\n",
    "\n",
    ".. [2] Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. \"Stochastic\n",
    "\tbackpropagation and approximate inference in deep generative models.\" arXiv\n",
    "\tpreprint arXiv:1401.4082 (2014).\n",
    "\n",
    "\t`<https://arxiv.org/abs/1401.4082>`_\n",
    "\"\"\"\n",
    "__date__ = \"November 2018 - November 2019\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.distributions import LowRankMultivariateNormal\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "# from ava.models.vae_dataset import SyllableDataset\n",
    "from ava.plotting.grid_plot import grid_plot\n",
    "\n",
    "\n",
    "X_SHAPE = (128,128)\n",
    "\"\"\"Processed spectrogram shape: ``[freq_bins, time_bins]``\"\"\"\n",
    "X_DIM = np.prod(X_SHAPE)\n",
    "\"\"\"Processed spectrogram dimension: ``freq_bins * time_bins``\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "\t\"\"\"Variational Autoencoder class for single-channel images.\n",
    "\n",
    "\tAttributes\n",
    "\t----------\n",
    "\tsave_dir : str, optional\n",
    "\t\tDirectory where the model is saved. Defaults to ``''``.\n",
    "\tlr : float, optional\n",
    "\t\tModel learning rate. Defaults to ``1e-3``.\n",
    "\tz_dim : int, optional\n",
    "\t\tLatent dimension. Defaults to ``32``.\n",
    "\tmodel_precision : float, optional\n",
    "\t\tPrecision of the observation model. Defaults to ``10.0``.\n",
    "\tdevice_name : {'cpu', 'cuda', 'auto'}, optional\n",
    "\t\tName of device to train the model on. When ``'auto'`` is passed,\n",
    "\t\t``'cuda'`` is chosen if ``torch.cuda.is_available()``, otherwise\n",
    "\t\t``'cpu'`` is chosen. Defaults to ``'auto'``.\n",
    "\n",
    "\tNotes\n",
    "\t-----\n",
    "\tThe model is trained to maximize the standard ELBO objective:\n",
    "\n",
    "\t.. math:: \\mathcal{L} = \\mathbb{E}_{q(z|x)} log p(x,z) + \\mathbb{H}[q(z|x)]\n",
    "\n",
    "\twhere :math:`p(x,z) = p(z)p(x|z)` and :math:`\\mathbb{H}` is differential\n",
    "\tentropy. The prior :math:`p(z)` is a unit spherical normal distribution. The\n",
    "\tconditional distribution :math:`p(x|z)` is set as a spherical normal\n",
    "\tdistribution to prevent overfitting. The variational distribution,\n",
    "\t:math:`q(z|x)` is an approximately rank-1 multivariate normal distribution.\n",
    "\tHere, :math:`q(z|x)` and :math:`p(x|z)` are parameterized by neural\n",
    "\tnetworks. Gradients are passed through stochastic layers via the\n",
    "\treparameterization trick, implemented by the PyTorch `rsample` method.\n",
    "\n",
    "\tThe dimensions of the network are hard-coded for use with 128 x 128\n",
    "\tspectrograms. Although a desired latent dimension can be passed to\n",
    "\t`__init__`, the dimensions of the network limit the practical range of\n",
    "\tvalues roughly 8 to 64 dimensions. Fiddling with the image dimensions will\n",
    "\trequire updating the parameters of the layers defined in `_build_network`.\n",
    "\t\"\"\"\n",
    "\n",
    "\tdef __init__(self, save_dir='', lr=1e-3, z_dim=32, model_precision=10.0, \n",
    "\t\tdevice_name=\"auto\"):\n",
    "\t\t\"\"\"Construct a VAE.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tsave_dir : str, optional\n",
    "\t\t\tDirectory where the model is saved. Defaults to the current working\n",
    "\t\t\tdirectory.\n",
    "\t\tlr : float, optional\n",
    "\t\t\tLearning rate of the ADAM optimizer. Defaults to 1e-3.\n",
    "\t\tz_dim : int, optional\n",
    "\t\t\tDimension of the latent space. Defaults to 32.\n",
    "\t\tmodel_precision : float, optional\n",
    "\t\t\tPrecision of the noise model, p(x|z) = N(mu(z), \\Lambda) where\n",
    "\t\t\t\\Lambda = model_precision * I. Defaults to 10.0.\n",
    "\t\tdevice_name: str, optional\n",
    "\t\t\tName of device to train the model on. Valid options are [\"cpu\",\n",
    "\t\t\t\"cuda\", \"auto\"]. \"auto\" will choose \"cuda\" if it is available.\n",
    "\t\t\tDefaults to \"auto\".\n",
    "\n",
    "\t\tNote\n",
    "\t\t----\n",
    "\t\t- The model is built before it's parameters can be loaded from a file.\n",
    "\t\t\tThis means `self.z_dim` must match `z_dim` of the model being\n",
    "\t\t\tloaded.\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(VAE, self).__init__()\n",
    "\t\tself.save_dir = save_dir\n",
    "\t\tself.lr = lr\n",
    "\t\tself.z_dim = z_dim\n",
    "\t\tself.model_precision = model_precision\n",
    "\t\tassert device_name != \"cuda\" or torch.cuda.is_available()\n",
    "\t\tif device_name == \"auto\":\n",
    "\t\t\tdevice_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\t\tself.device = torch.device(device_name)\n",
    "\t\tif self.save_dir != '' and not os.path.exists(self.save_dir):\n",
    "\t\t\tos.makedirs(self.save_dir)\n",
    "\t\tself._build_network()\n",
    "\t\tself.optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "\t\tself.epoch = 0\n",
    "\t\tself.loss = {'train':{}, 'test':{}}\n",
    "\t\tself.to(self.device)\n",
    "\n",
    "\n",
    "\tdef _build_network(self):\n",
    "\t\t\"\"\"Define all the network layers.\"\"\"\n",
    "\t\t# Encoder\n",
    "\t\tself.conv1 = nn.Conv2d(1, 8, 3,1,padding=1)\n",
    "\t\tself.conv2 = nn.Conv2d(8, 8, 3,2,padding=1)\n",
    "\t\tself.conv3 = nn.Conv2d(8, 16,3,1,padding=1)\n",
    "\t\tself.conv4 = nn.Conv2d(16,16,3,2,padding=1)\n",
    "\t\tself.conv5 = nn.Conv2d(16,24,3,1,padding=1)\n",
    "\t\tself.conv6 = nn.Conv2d(24,24,3,2,padding=1)\n",
    "\t\tself.conv7 = nn.Conv2d(24,32,3,1,padding=1)\n",
    "\t\tself.bn1 = nn.BatchNorm2d(1)\n",
    "\t\tself.bn2 = nn.BatchNorm2d(8)\n",
    "\t\tself.bn3 = nn.BatchNorm2d(8)\n",
    "\t\tself.bn4 = nn.BatchNorm2d(16)\n",
    "\t\tself.bn5 = nn.BatchNorm2d(16)\n",
    "\t\tself.bn6 = nn.BatchNorm2d(24)\n",
    "\t\tself.bn7 = nn.BatchNorm2d(24)\n",
    "\t\tself.fc1 = nn.Linear(8192,1024)\n",
    "\t\tself.fc2 = nn.Linear(1024,256)\n",
    "\t\tself.fc31 = nn.Linear(256,64)\n",
    "\t\tself.fc32 = nn.Linear(256,64)\n",
    "\t\tself.fc33 = nn.Linear(256,64)\n",
    "\t\tself.fc41 = nn.Linear(64,self.z_dim)\n",
    "\t\tself.fc42 = nn.Linear(64,self.z_dim)\n",
    "\t\tself.fc43 = nn.Linear(64,self.z_dim)\n",
    "\t\t# Decoder\n",
    "\t\tself.fc5 = nn.Linear(self.z_dim,64)\n",
    "\t\tself.fc6 = nn.Linear(64,256)\n",
    "\t\tself.fc7 = nn.Linear(256,1024)\n",
    "\t\tself.fc8 = nn.Linear(1024,8192)\n",
    "\t\tself.convt1 = nn.ConvTranspose2d(32,24,3,1,padding=1)\n",
    "\t\tself.convt2 = nn.ConvTranspose2d(24,24,3,2,padding=1,output_padding=1)\n",
    "\t\tself.convt3 = nn.ConvTranspose2d(24,16,3,1,padding=1)\n",
    "\t\tself.convt4 = nn.ConvTranspose2d(16,16,3,2,padding=1,output_padding=1)\n",
    "\t\tself.convt5 = nn.ConvTranspose2d(16,8,3,1,padding=1)\n",
    "\t\tself.convt6 = nn.ConvTranspose2d(8,8,3,2,padding=1,output_padding=1)\n",
    "\t\tself.convt7 = nn.ConvTranspose2d(8,1,3,1,padding=1)\n",
    "\t\tself.bn8 = nn.BatchNorm2d(32)\n",
    "\t\tself.bn9 = nn.BatchNorm2d(24)\n",
    "\t\tself.bn10 = nn.BatchNorm2d(24)\n",
    "\t\tself.bn11 = nn.BatchNorm2d(16)\n",
    "\t\tself.bn12 = nn.BatchNorm2d(16)\n",
    "\t\tself.bn13 = nn.BatchNorm2d(8)\n",
    "\t\tself.bn14 = nn.BatchNorm2d(8)\n",
    "\n",
    "\n",
    "\tdef _get_layers(self):\n",
    "\t\t\"\"\"Return a dictionary mapping names to network layers.\"\"\"\n",
    "\t\treturn {'fc1':self.fc1, 'fc2':self.fc2, 'fc31':self.fc31,\n",
    "\t\t\t\t'fc32':self.fc32, 'fc33':self.fc33, 'fc41':self.fc41,\n",
    "\t\t\t\t'fc42':self.fc42, 'fc43':self.fc43, 'fc5':self.fc5,\n",
    "\t\t\t\t'fc6':self.fc6, 'fc7':self.fc7, 'fc8':self.fc8, 'bn1':self.bn1,\n",
    "\t\t\t\t'bn2':self.bn2, 'bn3':self.bn3, 'bn4':self.bn4, 'bn5':self.bn5,\n",
    "\t\t\t\t'bn6':self.bn6, 'bn7':self.bn7, 'bn8':self.bn8, 'bn9':self.bn9,\n",
    "\t\t\t\t'bn10':self.bn10, 'bn11':self.bn11, 'bn12':self.bn12,\n",
    "\t\t\t\t'bn13':self.bn13, 'bn14':self.bn14, 'conv1':self.conv1,\n",
    "\t\t\t\t'conv2':self.conv2, 'conv3':self.conv3, 'conv4':self.conv4,\n",
    "\t\t\t\t'conv5':self.conv5, 'conv6':self.conv6, 'conv7':self.conv7,\n",
    "\t\t\t\t'convt1':self.convt1, 'convt2':self.convt2,\n",
    "\t\t\t\t'convt3':self.convt3, 'convt4':self.convt4,\n",
    "\t\t\t\t'convt5':self.convt5, 'convt6':self.convt6,\n",
    "\t\t\t\t'convt7':self.convt7}\n",
    "\n",
    "\n",
    "\tdef encode(self, x):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute :math:`q(z|x)`.\n",
    "\n",
    "\t\t.. math:: q(z|x) = \\mathcal{N}(\\mu, \\Sigma)\n",
    "\t\t.. math:: \\Sigma = u u^{T} + \\mathtt{diag}(d)\n",
    "\n",
    "\t\twhere :math:`\\mu`, :math:`u`, and :math:`d` are deterministic functions\n",
    "\t\tof `x` and :math:`\\Sigma` denotes a covariance matrix.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tx : torch.Tensor\n",
    "\t\t\tThe input images, with shape: ``[batch_size, height=128,\n",
    "\t\t\twidth=128]``\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tmu : torch.Tensor\n",
    "\t\t\tPosterior mean, with shape ``[batch_size, self.z_dim]``\n",
    "\t\tu : torch.Tensor\n",
    "\t\t\tPosterior covariance factor, as defined above. Shape:\n",
    "\t\t\t``[batch_size, self.z_dim]``\n",
    "\t\td : torch.Tensor\n",
    "\t\t\tPosterior diagonal factor, as defined above. Shape:\n",
    "\t\t\t``[batch_size, self.z_dim]``\n",
    "\t\t\"\"\"\n",
    "\t\tx = x.unsqueeze(1)\n",
    "\t\tx = F.relu(self.conv1(self.bn1(x)))\n",
    "\t\tx = F.relu(self.conv2(self.bn2(x)))\n",
    "\t\tx = F.relu(self.conv3(self.bn3(x)))\n",
    "\t\tx = F.relu(self.conv4(self.bn4(x)))\n",
    "\t\tx = F.relu(self.conv5(self.bn5(x)))\n",
    "\t\tx = F.relu(self.conv6(self.bn6(x)))\n",
    "\t\tx = F.relu(self.conv7(self.bn7(x)))\n",
    "\t\tx = x.view(-1, 8192)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tmu = F.relu(self.fc31(x))\n",
    "\t\tmu = self.fc41(mu)\n",
    "\t\tu = F.relu(self.fc32(x))\n",
    "\t\tu = self.fc42(u).unsqueeze(-1) # Last dimension is rank \\Sigma = 1.\n",
    "\t\td = F.relu(self.fc33(x))\n",
    "\t\td = torch.exp(self.fc43(d)) # d must be positive.\n",
    "\t\treturn mu, u, d\n",
    "\n",
    "\n",
    "\tdef decode(self, z):\n",
    "\t\t\"\"\"\n",
    "\t\tCompute :math:`p(x|z)`.\n",
    "\n",
    "\t\t.. math:: p(x|z) = \\mathcal{N}(\\mu, \\Lambda)\n",
    "\n",
    "\t\t.. math:: \\Lambda = \\mathtt{model\\_precision} \\cdot I\n",
    "\n",
    "\t\twhere :math:`\\mu` is a deterministic function of `z`, :math:`\\Lambda` is\n",
    "\t\ta precision matrix, and :math:`I` is the identity matrix.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tz : torch.Tensor\n",
    "\t\t\tBatch of latent samples with shape ``[batch_size, self.z_dim]``\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tx : torch.Tensor\n",
    "\t\t\tBatch of means mu, described above. Shape: ``[batch_size,\n",
    "\t\t\tX_DIM=128*128]``\n",
    "\t\t\"\"\"\n",
    "\t\tz = F.relu(self.fc5(z))\n",
    "\t\tz = F.relu(self.fc6(z))\n",
    "\t\tz = F.relu(self.fc7(z))\n",
    "\t\tz = F.relu(self.fc8(z))\n",
    "\t\tz = z.view(-1,32,16,16)\n",
    "\t\tz = F.relu(self.convt1(self.bn8(z)))\n",
    "\t\tz = F.relu(self.convt2(self.bn9(z)))\n",
    "\t\tz = F.relu(self.convt3(self.bn10(z)))\n",
    "\t\tz = F.relu(self.convt4(self.bn11(z)))\n",
    "\t\tz = F.relu(self.convt5(self.bn12(z)))\n",
    "\t\tz = F.relu(self.convt6(self.bn13(z)))\n",
    "\t\tz = self.convt7(self.bn14(z))\n",
    "\t\treturn z.view(-1, X_DIM)\n",
    "\n",
    "\n",
    "\tdef forward(self, x, return_latent_rec=False):\n",
    "\t\t\"\"\"\n",
    "\t\tSend `x` round trip and compute a loss.\n",
    "\n",
    "\t\tIn more detail: Given `x`, compute :math:`q(z|x)` and sample:\n",
    "\t\t:math:`\\hat{z} \\sim q(z|x)` . Then compute :math:`\\log p(x|\\hat{z})`,\n",
    "\t\tthe log-likelihood of `x`, the input, given :math:`\\hat{z}`, the latent\n",
    "\t\tsample. We will also need the likelihood of :math:`\\hat{z}` under the\n",
    "\t\tmodel's prior: :math:`p(\\hat{z})`, and the entropy of the latent\n",
    "\t\tconditional distribution, :math:`\\mathbb{H}[q(z|x)]` . ELBO can then be\n",
    "\t\testimated as:\n",
    "\n",
    "\t\t.. math:: \\\\frac{1}{N} \\sum_{i=1}^N \\mathbb{E}_{\\hat{z} \\sim q(z|x_i)}\n",
    "\t\t\t\\log p(x_i,\\hat{z}) + \\mathbb{H}[q(z|x_i)]\n",
    "\n",
    "\t\twhere :math:`N` denotes the number of samples from the data distribution\n",
    "\t\tand the expectation is estimated using a single latent sample,\n",
    "\t\t:math:`\\hat{z}`. In practice, the outer expectation is estimated using\n",
    "\t\tminibatches.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tx : torch.Tensor\n",
    "\t\t\tA batch of samples from the data distribution (spectrograms).\n",
    "\t\t\tShape: ``[batch_size, height=128, width=128]``\n",
    "\t\treturn_latent_rec : bool, optional\n",
    "\t\t\tWhether to return latent means and reconstructions. Defaults to\n",
    "\t\t\t``False``.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tloss : torch.Tensor\n",
    "\t\t\tNegative ELBO times the batch size. Shape: ``[]``\n",
    "\t\tlatent : numpy.ndarray, if `return_latent_rec`\n",
    "\t\t\tLatent means. Shape: ``[batch_size, self.z_dim]``\n",
    "\t\treconstructions : numpy.ndarray, if `return_latent_rec`\n",
    "\t\t\tReconstructed means. Shape: ``[batch_size, height=128, width=128]``\n",
    "\t\t\"\"\"\n",
    "\t\tmu, u, d = self.encode(x)\n",
    "\t\tlatent_dist = LowRankMultivariateNormal(mu, u, d)\n",
    "\t\tz = latent_dist.rsample()\n",
    "\t\tx_rec = self.decode(z)\n",
    "\t\t# E_{q(z|x)} p(z)\n",
    "\t\telbo = -0.5 * (torch.sum(torch.pow(z,2)) + self.z_dim * np.log(2*np.pi))\n",
    "\t\t# E_{q(z|x)} p(x|z)\n",
    "\t\tpxz_term = -0.5 * X_DIM * (np.log(2*np.pi/self.model_precision))\n",
    "\t\tl2s = torch.sum(torch.pow(x.view(x.shape[0],-1) - x_rec, 2), dim=1)\n",
    "\t\tpxz_term = pxz_term - 0.5 * self.model_precision * torch.sum(l2s)\n",
    "\t\telbo = elbo + pxz_term\n",
    "\t\t# H[q(z|x)]\n",
    "\t\telbo = elbo + torch.sum(latent_dist.entropy())\n",
    "\t\tif return_latent_rec:\n",
    "\t\t\treturn -elbo, z.detach().cpu().numpy(), \\\n",
    "\t\t\t\tx_rec.view(-1, X_SHAPE[0], X_SHAPE[1]).detach().cpu().numpy()\n",
    "\t\treturn -elbo\n",
    "\n",
    "\n",
    "\tdef train_epoch(self, train_loader):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain the model for a single epoch.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\ttrain_loader : torch.utils.data.Dataloader\n",
    "\t\t\tava.models.vae_dataset.SyllableDataset Dataloader for training set\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\telbo : float\n",
    "\t\t\tA biased estimate of the ELBO, estimated using samples from\n",
    "\t\t\t`train_loader`.\n",
    "\t\t\"\"\"\n",
    "\t\tself.train()\n",
    "\t\ttrain_loss = 0.0\n",
    "\t\tfor batch_idx, data in enumerate(train_loader):\n",
    "\t\t\tdata = data[0]            \n",
    "\t\t\tself.optimizer.zero_grad()\n",
    "\t\t\tdata = data.to(self.device)\n",
    "\t\t\tloss = self.forward(data)\n",
    "\t\t\ttrain_loss += loss.item()\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tself.optimizer.step()\n",
    "\t\ttrain_loss /= len(train_loader.dataset)\n",
    "\t\tprint('Epoch: {} Average loss: {:.4f}'.format(self.epoch, \\\n",
    "\t\t\t\ttrain_loss))\n",
    "\t\tself.epoch += 1\n",
    "\t\treturn train_loss\n",
    "\n",
    "\tdef test_epoch(self, test_loader):\n",
    "\t\t\"\"\"\n",
    "\t\tTest the model on a held-out test set, return an ELBO estimate.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\ttest_loader : torch.utils.data.Dataloader\n",
    "\t\t\tava.models.vae_dataset.SyllableDataset Dataloader for test set\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\telbo : float\n",
    "\t\t\tAn unbiased estimate of the ELBO, estimated using samples from\n",
    "\t\t\t`test_loader`.\n",
    "\t\t\"\"\"\n",
    "\t\tself.eval()\n",
    "\t\ttest_loss = 0.0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor i, data in enumerate(test_loader):\n",
    "\t\t\t\tdata = data[0]\n",
    "\t\t\t\tdata = data.to(self.device)\n",
    "\t\t\t\tloss = self.forward(data)\n",
    "\t\t\t\ttest_loss += loss.item()\n",
    "\t\ttest_loss /= len(test_loader.dataset)\n",
    "\t\tprint('Test loss: {:.4f}'.format(test_loss))\n",
    "\t\treturn test_loss\n",
    "\n",
    "\tdef train_loop(self, loaders, epochs=100, test_freq=2, save_freq=10,\n",
    "\t\tvis_freq=1):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain the model for multiple epochs, testing and saving along the way.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tloaders : dictionary\n",
    "\t\t\tDictionary mapping the keys ``'test'`` and ``'train'`` to respective\n",
    "\t\t\ttorch.utils.data.Dataloader objects.\n",
    "\t\tepochs : int, optional\n",
    "\t\t\tNumber of (possibly additional) epochs to train the model for.\n",
    "\t\t\tDefaults to ``100``.\n",
    "\t\ttest_freq : int, optional\n",
    "\t\t\tTesting is performed every `test_freq` epochs. Defaults to ``2``.\n",
    "\t\tsave_freq : int, optional\n",
    "\t\t\tThe model is saved every `save_freq` epochs. Defaults to ``10``.\n",
    "\t\tvis_freq : int, optional\n",
    "\t\t\tSyllable reconstructions are plotted every `vis_freq` epochs.\n",
    "\t\t\tDefaults to ``1``.\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"=\"*40)\n",
    "\t\tprint(\"Training: epochs\", self.epoch, \"to\", self.epoch+epochs-1)\n",
    "\t\tprint(\"Training set:\", len(loaders['train'].dataset))\n",
    "\t\tprint(\"Test set:\", len(loaders['test'].dataset))\n",
    "\t\tprint(\"=\"*40)\n",
    "\t\t# For some number of epochs...\n",
    "\t\tfor epoch in range(self.epoch, self.epoch+epochs):\n",
    "\t\t\t# Run through the training data and record a loss.\n",
    "\t\t\tloss = self.train_epoch(loaders['train'])\n",
    "\t\t\tself.loss['train'][epoch] = loss\n",
    "\t\t\t# Run through the test data and record a loss.\n",
    "\t\t\tif (test_freq is not None) and (epoch % test_freq == 0):\n",
    "\t\t\t\tloss = self.test_epoch(loaders['test'])\n",
    "\t\t\t\tself.loss['test'][epoch] = loss\n",
    "\t\t\t# Save the model.\n",
    "\t\t\tif (save_freq is not None) and (epoch % save_freq == 0) and \\\n",
    "\t\t\t\t\t(epoch > 0):\n",
    "\t\t\t\tfilename = \"checkpoint_\"+str(epoch).zfill(3)+'.tar'\n",
    "\t\t\t\tself.save_state(filename)\n",
    "\t\t\t# Plot reconstructions.\n",
    "\t\t\tif (vis_freq is not None) and (epoch % vis_freq == 0):\n",
    "\t\t\t\tself.visualize(loaders['test'])\n",
    "\n",
    "\n",
    "\tdef save_state(self, filename):\n",
    "\t\t\"\"\"Save all the model parameters to the given file.\"\"\"\n",
    "\t\tlayers = self._get_layers()\n",
    "\t\tstate = {}\n",
    "\t\tfor layer_name in layers:\n",
    "\t\t\tstate[layer_name] = layers[layer_name].state_dict()\n",
    "\t\tstate['optimizer_state'] = self.optimizer.state_dict()\n",
    "\t\tstate['loss'] = self.loss\n",
    "\t\tstate['z_dim'] = self.z_dim\n",
    "\t\tstate['epoch'] = self.epoch\n",
    "\t\tstate['lr'] = self.lr\n",
    "\t\tstate['save_dir'] = self.save_dir\n",
    "\t\tfilename = os.path.join(self.save_dir, filename)\n",
    "\t\ttorch.save(state, filename)\n",
    "\n",
    "\n",
    "\tdef load_state(self, filename):\n",
    "\t\t\"\"\"\n",
    "\t\tLoad all the model parameters from the given ``.tar`` file.\n",
    "\n",
    "\t\tThe ``.tar`` file should be written by `self.save_state`.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tfilename : str\n",
    "\t\t\tFile containing a model state.\n",
    "\n",
    "\t\tNote\n",
    "\t\t----\n",
    "\t\t- `self.lr`, `self.save_dir`, and `self.z_dim` are not loaded.\n",
    "\t\t\"\"\"\n",
    "\t\tcheckpoint = torch.load(filename, map_location=self.device)\n",
    "\t\tassert checkpoint['z_dim'] == self.z_dim\n",
    "\t\tlayers = self._get_layers()\n",
    "\t\tfor layer_name in layers:\n",
    "\t\t\tlayer = layers[layer_name]\n",
    "\t\t\tlayer.load_state_dict(checkpoint[layer_name])\n",
    "\t\tself.optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "\t\tself.loss = checkpoint['loss']\n",
    "\t\tself.epoch = checkpoint['epoch']\n",
    "\n",
    "\tdef visualize(self, loader, num_specs=5, gap=(2,6), \\\n",
    "\t\tsave_filename='reconstruction.pdf'):\n",
    "\t\t\"\"\"\n",
    "\t\tPlot spectrograms and their reconstructions.\n",
    "\n",
    "\t\tSpectrograms are chosen at random from the Dataloader Dataset.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tloader : torch.utils.data.Dataloader\n",
    "\t\t\tSpectrogram Dataloader\n",
    "\t\tnum_specs : int, optional\n",
    "\t\t\tNumber of spectrogram pairs to plot. Defaults to ``5``.\n",
    "\t\tgap : int or tuple of two ints, optional\n",
    "\t\t\tThe vertical and horizontal gap between images, in pixels. Defaults\n",
    "\t\t\tto ``(2,6)``.\n",
    "\t\tsave_filename : str, optional\n",
    "\t\t\tWhere to save the plot, relative to `self.save_dir`. Defaults to\n",
    "\t\t\t``'temp.pdf'``.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tspecs : numpy.ndarray\n",
    "\t\t\tSpectgorams from `loader`.\n",
    "\t\trec_specs : numpy.ndarray\n",
    "\t\t\tCorresponding spectrogram reconstructions.\n",
    "\t\t\"\"\"\n",
    "\t\t# Collect random indices.\n",
    "\t\tassert num_specs <= len(loader.dataset) and num_specs >= 1\n",
    "\t\tindices = np.random.choice(np.arange(len(loader.dataset)),\n",
    "\t\t\tsize=num_specs,replace=False)\n",
    "\t\t# Retrieve spectrograms from the loader.\n",
    "\t\tspecs = torch.stack(loader.dataset[indices][0]).to(self.device)\n",
    "\t\t# Get resonstructions.\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t_, _, rec_specs = self.forward(specs, return_latent_rec=True)\n",
    "\t\tspecs = specs.detach().cpu().numpy()\n",
    "\t\tall_specs = np.stack([specs, rec_specs])\n",
    "\t\t# Plot.\n",
    "\t\tsave_filename = os.path.join(self.save_dir, save_filename)\n",
    "\t\tgrid_plot(all_specs, gap=gap, filename=save_filename)\n",
    "\t\treturn specs, rec_specs\n",
    "\tdef get_latent(self, loader):\n",
    "\t\t\"\"\"\n",
    "\t\tGet latent means for all syllable in the given loader.\n",
    "\n",
    "\t\tParameters\n",
    "\t\t----------\n",
    "\t\tloader : torch.utils.data.Dataloader\n",
    "\t\t\tava.models.vae_dataset.SyllableDataset Dataloader.\n",
    "\n",
    "\t\tReturns\n",
    "\t\t-------\n",
    "\t\tlatent : numpy.ndarray\n",
    "\t\t\tLatent means. Shape: ``[len(loader.dataset), self.z_dim]``\n",
    "\n",
    "\t\tNote\n",
    "\t\t----\n",
    "\t\t- Make sure your loader is not set to shuffle if you're going to match\n",
    "\t\t  these with labels or other fields later.\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"Reaching here!\")\n",
    "\t\tlatent = np.zeros((len(loader.dataset), self.z_dim))\n",
    "\t\tlatent_list = []\n",
    "\t\tlatent_filename = []\n",
    "\t\tlatent_onset_offset=[]\n",
    "\t\ti = 0\n",
    "\t\tfor data in loader:\n",
    "# \t\t\tfilename= data[1]\n",
    "\t\t\tonset_offset=data[1]\n",
    "\t\t\tdata = data[0]    \n",
    "\t\t\tdata = data.to(self.device)\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tmu, _, _ = self.encode(data)\n",
    "\t\t\tmu = mu.detach().cpu().numpy()\n",
    "\t\t\tlatent[i:i+len(mu)] = mu\n",
    "\t\t\ti += len(mu)\n",
    "# \t\t\tlatent_filename.append(filename)\n",
    "\t\t\tlatent_onset_offset.append(onset_offset)\n",
    "\t\t\tlatent_list.append(mu)        \n",
    "# \t\treturn latent,latent_filename,latent_onset_offset\n",
    "\t\treturn latent,latent_onset_offset, latent_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "achint-env2",
   "language": "python",
   "name": "achint-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
